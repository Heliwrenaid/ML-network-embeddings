{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "collab_main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "vector_len = 512"
      ],
      "metadata": {
        "id": "Kl02usxch85v"
      },
      "execution_count": 406,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 407,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx6fbGgA--sj",
        "outputId": "f8133961-f283-4045-bf38-4464fce12112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: node2vec in /usr/local/lib/python3.7/dist-packages (0.4.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.7/dist-packages (from node2vec) (1.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from node2vec) (2.6.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from node2vec) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from node2vec) (4.64.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from node2vec) (3.6.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim->node2vec) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->node2vec) (6.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (6.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pip install node2vec tensorflow\n",
        "!pip install gensim \n",
        "from deepwalk_config import *\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optionally load copy\n",
        "#!7z x copy.zip -o/content"
      ],
      "metadata": {
        "id": "VjRtk7G6YSr0"
      },
      "execution_count": 408,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**-------------- Functions --------------**"
      ],
      "metadata": {
        "id": "zQjUzHbD-txn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# choose links from AS file\n",
        "# samples_number for each link type (peer/customer)\n",
        "\n",
        "def get_as_data(as_relation_filename, samples_number):\n",
        "  as_relation_file = open(as_relation_filename, 'r')\n",
        "\n",
        "  peers = 0\n",
        "  customers = 0\n",
        "\n",
        "  X = []\n",
        "  Y = []\n",
        "\n",
        "  for line in as_relation_file:\n",
        "      if line.startswith('#'):\n",
        "          continue\n",
        "      data = line.split('|')\n",
        "\n",
        "      if '0' in data[2]:\n",
        "          if peers < samples_number:\n",
        "            X.append([data[0], data[1]])\n",
        "            Y.append(data[2])\n",
        "            peers += 1\n",
        "      else:\n",
        "          if customers < samples_number:\n",
        "            X.append([data[0], data[1]])\n",
        "            Y.append(data[2])\n",
        "            customers += 1\n",
        "  return X, Y\n",
        "\n",
        "\n",
        "def get_as_data2(as_relation_filename, samples_number):\n",
        "  as_relation_file = open(as_relation_filename, 'r')\n",
        "\n",
        "  peers = 0\n",
        "\n",
        "  X = []\n",
        "  Y = []\n",
        "\n",
        "  for line in as_relation_file:\n",
        "      if line.startswith('#'):\n",
        "          continue\n",
        "      data = line.split('|')\n",
        "\n",
        "      if peers < samples_number:\n",
        "        X.append([data[0], data[1]])\n",
        "        Y.append(data[2])\n",
        "        peers += 1\n",
        "       \n",
        "  return X, Y\n",
        "\n",
        "def get_as_data3(as_relation_filename, samples_number, skip):\n",
        "  as_relation_file = open(as_relation_filename, 'r')\n",
        "\n",
        "  peers = 0\n",
        "  skip_ = 0\n",
        "\n",
        "  X = []\n",
        "  Y = []\n",
        "\n",
        "  for line in as_relation_file:\n",
        "      if line.startswith('#'):\n",
        "          continue\n",
        "\n",
        "      if skip_ < skip:\n",
        "        skip_ += 1\n",
        "        continue\n",
        "        \n",
        "      data = line.split('|')\n",
        "\n",
        "      if peers < samples_number:\n",
        "        X.append([data[0], data[1]])\n",
        "        Y.append(data[2])\n",
        "        peers += 1\n",
        "       \n",
        "  return X, Y\n",
        "\n",
        "\n",
        "\n",
        "import csv\n",
        "\n",
        "# create dataset for neural network in format:\n",
        "# [start_node_embedding], [end_node_embedding], [link_type]\n",
        "def create_dataset(X, Y, X_embed, dataset_filename):\n",
        "\n",
        "  out = open(dataset_filename, 'w')\n",
        "  writer = csv.writer(out)\n",
        "\n",
        "  for i in range(len(X)):\n",
        "      data = []\n",
        "      data.extend(X_embed[X[i][0]])\n",
        "      data.extend(X_embed[X[i][1]])\n",
        "      if '0' in Y[i]:\n",
        "          data.append('0')\n",
        "      else:\n",
        "          data.append('1')\n",
        "      \n",
        "      writer.writerow(data)\n",
        "\n",
        "  out.close()\n",
        "\n",
        "\n",
        "# count links\n",
        "def display_link_stats(Y):\n",
        "\n",
        "  peers = 0\n",
        "  customers = 0\n",
        "\n",
        "  for y in Y:\n",
        "      if int(y) == 0:\n",
        "          peers = peers + 1\n",
        "      else:\n",
        "          customers = customers + 1\n",
        "\n",
        "  print('Peer:', peers, '\\n  Customer:', customers)\n",
        "\n",
        "# embeddings methods ----------------------------------\n",
        "\n",
        "import networkx as nx\n",
        "from node2vec import Node2Vec\n",
        "\n",
        "def node2vec_get_embeddings(as_data):\n",
        "\n",
        "  embedding_filename = \"embeddings_tmp_file\"\n",
        "\n",
        "  # Create a graph \n",
        "  graph = nx.Graph()\n",
        "  for AS in as_data:\n",
        "      graph.add_edge(AS[0], AS[1])\n",
        "\n",
        "  # Precompute probabilities and generate walks - **ON WINDOWS ONLY WORKS WITH workers=1**\n",
        "  node2vec = Node2Vec(graph, dimensions=vector_len, walk_length=30, num_walks=200, workers=4)  # Use temp_folder for big graphs\n",
        "\n",
        "  # Embed nodes\n",
        "  model = node2vec.fit(window=10, min_count=1, batch_words=4)  # Any keywords acceptable by gensim.Word2Vec can be passed, `dimensions` and `workers` are automatically passed (from the Node2Vec constructor)\n",
        "  \n",
        "  # Save embeddings for later use\n",
        "  model.wv.save_word2vec_format(embedding_filename)\n",
        "\n",
        "  embeddings_file = open(embedding_filename,'r')\n",
        "  node_embeddings = {}\n",
        "\n",
        "  i = 0\n",
        "  for line in embeddings_file:\n",
        "      if i == 0:\n",
        "          i = i + 1\n",
        "          continue\n",
        "      data = line.split(' ')\n",
        "      node_embeddings[data[0]] = data[1:]\n",
        "\n",
        "  return node_embeddings\n",
        "\n",
        "\n",
        "def deepwalk_get_embeddings(as_data, vector_len):\n",
        "\n",
        "  embedding_filename = \"embeddings_tmp_file\"\n",
        " \n",
        " # Create a graph \n",
        "  graph = nx.Graph()\n",
        "  for AS in as_data:\n",
        "      graph.add_edge(AS[0],AS[1])\n",
        "\n",
        "  # Precompute probabilities and generate walks - **ON WINDOWS ONLY WORKS WITH workers=1**\n",
        "  model = DeepWalk(graph,walk_length=10,num_walks=80,workers=1)  # Use temp_folder for big graphs\n",
        "  \n",
        "  # Embed nodes\n",
        "  model.train(embed_size=vector_len)# train model\n",
        "\n",
        "  # Save embeddings for later use\n",
        "  model.w2v_model.wv.save_word2vec_format(embedding_filename)\n",
        "\n",
        "  embeddings_file = open(embedding_filename,'r')\n",
        "  node_embeddings = {}\n",
        "\n",
        "  i = 0\n",
        "  for line in embeddings_file:\n",
        "      if i == 0:\n",
        "          i = i + 1\n",
        "          continue\n",
        "      data = line.split(' ')\n",
        "      node_embeddings[data[0]] = data[1:]\n",
        "\n",
        "  return node_embeddings"
      ],
      "metadata": {
        "id": "ELREEHbYkPeE"
      },
      "execution_count": 439,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**-------------- Create datasets --------------**"
      ],
      "metadata": {
        "id": "tDx5l0L-_TKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create model of neural network\n",
        "\n",
        "def create_model(vector_len):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(32, input_dim=2*vector_len, activation='relu'))\n",
        "  model.add(Dense(16, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  # Compile model\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "u2l3-KdHIsw0"
      },
      "execution_count": 440,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "vector_sizes = []\n",
        "accuracy = []\n",
        "for vector_len in [4, 8, 16, 32, 64, 128, 256]:\n",
        "  print(\"Vector length:\", vector_len)\n",
        "  #create embeddings and basic dataset\n",
        "  samples = 1000\n",
        "\n",
        "  X, Y = get_as_data('as-rank.caida.peercones-with-IX.txt', samples / 2) # balanced\n",
        "  #display_link_stats(Y)\n",
        "\n",
        "  X_embed = deepwalk_get_embeddings(X, vector_len)\n",
        "  create_dataset(X, Y, X_embed, 'dataset_basic.csv')\n",
        "\n",
        "  # create datasets for training and testing --------------------------------\n",
        "\n",
        "\n",
        "  def split_data(X, Y):\n",
        "    \n",
        "    X_0 = []\n",
        "    Y_0 = []\n",
        "\n",
        "    X_1 = []\n",
        "    Y_1 = []\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        if Y[i][0] == '0':\n",
        "          X_0.append(X[i])\n",
        "          Y_0.append([0])\n",
        "        else:\n",
        "          X_1.append(X[i])\n",
        "          Y_1.append([1])\n",
        "          \n",
        "    return X_0, Y_0, X_1, Y_1\n",
        "\n",
        "  def write_csv(filename, X, Y):\n",
        "    out = open(filename, 'w')\n",
        "    writer = csv.writer(out)\n",
        "    for i in range(len(X)):\n",
        "      data = []\n",
        "      data.extend(X[i])\n",
        "      data.extend(Y[i])\n",
        "      writer.writerow(data)\n",
        "\n",
        "\n",
        "  X = []\n",
        "  Y = []\n",
        "\n",
        "  with open('dataset_basic.csv', mode='r') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    for row in csv_reader:\n",
        "      X.append(row[0:2*vector_len])\n",
        "      Y.append(row[2*vector_len:])\n",
        "      \n",
        "\n",
        "  X_0, Y_0, X_1, Y_1 = split_data(X, Y)\n",
        "\n",
        "  X.clear()\n",
        "  Y.clear()\n",
        "\n",
        "  X.extend(X_0[0:450])\n",
        "  X.extend(X_1[0:450])\n",
        "\n",
        "  Y.extend(Y_0[0:450])\n",
        "  Y.extend(Y_1[0:450])\n",
        "\n",
        "  write_csv('dataset_balanced.csv', X, Y)\n",
        "\n",
        "  X.clear()\n",
        "  Y.clear()\n",
        "  X.extend(X_0[450:500])\n",
        "  X.extend(X_1[450:500])\n",
        "\n",
        "  Y.extend(Y_0[450:500])\n",
        "  Y.extend(Y_1[450:500])\n",
        "\n",
        "  write_csv('test_dataset_balanced.csv', X, Y)\n",
        "\n",
        "  # create, train and save model --------------------------------------\n",
        "\n",
        "\n",
        "  # load dataset\n",
        "  dataframe = read_csv(\"dataset_balanced.csv\", header=None)\n",
        "  #dataframe = shuffle(dataframe)\n",
        "  dataset = dataframe.values\n",
        "\n",
        "  # split into input (X) and output (Y) variables\n",
        "  X = dataset[:,0:2*vector_len].astype(float)\n",
        "  Y = dataset[:,2*vector_len].astype(int)\n",
        "\n",
        "  #display_link_stats(Y)\n",
        "  # evaluate model with standardized dataset\n",
        "  n_split=2\n",
        "  use_cross_validation = True\n",
        "\n",
        "  model=create_model(vector_len)\n",
        "\n",
        "  if (use_cross_validation == False):\n",
        "    history = model.fit(X, Y, epochs=8, batch_size=40, verbose=0)\n",
        "  else:\n",
        "    for train_index,test_index in KFold(n_splits=n_split, shuffle=True).split(X):\n",
        "\n",
        "      x_train,x_test=X[train_index],X[test_index]\n",
        "      y_train,y_test=Y[train_index],Y[test_index]\n",
        "      validation_data = [x_test, y_test];\n",
        "      \n",
        "      history = model.fit(x_train, y_train, epochs=8, batch_size=40, validation_data=validation_data, verbose=0)\n",
        "\n",
        "  model.save(\"model\")\n",
        "\n",
        "  # evaluate loaded model ------------------------------------------\n",
        "\n",
        "  # load dataset\n",
        "  dataframe = read_csv(\"test_dataset_balanced.csv\", header=None)\n",
        "\n",
        "  dataset = dataframe.values\n",
        "\n",
        "  # split into input (X) and output (Y) variables\n",
        "  X = dataset[:,0:2*vector_len].astype(float)\n",
        "  Y = dataset[:,2*vector_len]\n",
        "\n",
        "  #display_link_stats(Y)\n",
        "\n",
        "  model = keras.models.load_model('model')\n",
        "  predictions = (model.predict(X) > 0.5).astype(int)\n",
        "\n",
        "  success = 0\n",
        "  for i in range(len(X)):\n",
        "    #print(Y[i], \" -> \", predictions[i])\n",
        "    if int(predictions[i]) == int(Y[i]):\n",
        "      success += 1\n",
        "  print(\"Result:\", success/len(X)*100)\n",
        "  vector_sizes.append(vector_len)\n",
        "  accuracy.append(success/len(X)*100)\n",
        "\n",
        "\n",
        "plt.bar(vector_sizes, accuracy)\n",
        "plt.title('Embedding length vs accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Embedding length')\n",
        "plt.show()\n",
        "print(vector_sizes)\n",
        "print(accuracy)\n"
      ],
      "metadata": {
        "id": "a7yHNam1_UmR",
        "outputId": "b36a7fd4-d123-4154-e5c6-c43135fd5ff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 469,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector length: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning embedding vectors...\n",
            "Learning embedding vectors done!\n",
            "INFO:tensorflow:Assets written to: model/assets\n",
            "Result: 99.0\n",
            "Vector length: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning embedding vectors...\n",
            "Learning embedding vectors done!\n",
            "INFO:tensorflow:Assets written to: model/assets\n",
            "Result: 100.0\n",
            "Vector length: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning embedding vectors...\n",
            "Learning embedding vectors done!\n",
            "INFO:tensorflow:Assets written to: model/assets\n",
            "Result: 100.0\n",
            "Vector length: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning embedding vectors...\n",
            "Learning embedding vectors done!\n",
            "INFO:tensorflow:Assets written to: model/assets\n",
            "Result: 100.0\n",
            "Vector length: 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning embedding vectors...\n",
            "Learning embedding vectors done!\n",
            "INFO:tensorflow:Assets written to: model/assets\n",
            "Result: 99.0\n",
            "Vector length: 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning embedding vectors...\n",
            "Learning embedding vectors done!\n",
            "INFO:tensorflow:Assets written to: model/assets\n",
            "Result: 100.0\n",
            "Vector length: 256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning embedding vectors...\n",
            "Learning embedding vectors done!\n",
            "INFO:tensorflow:Assets written to: model/assets\n",
            "Result: 100.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4, 8, 16, 32, 64, 128, 256]\n",
            "[99.0, 100.0, 100.0, 100.0, 99.0, 100.0, 100.0]\n"
          ]
        }
      ]
    }
  ]
}